{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from direct.preprocessor import Preprocessor, pose_inv, SceneData\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "dir = \"wood\"\n",
    "\n",
    "demo_rgb = np.array(Image.open(\"../data/{0}/demo_head_rgb.png\".format(dir)))\n",
    "demo_depth = np.array(Image.open(\"../data/{0}/demo_head_depth.png\".format(dir)))\n",
    "demo_mask = np.array(Image.open(\"../data/{0}/demo_head_seg.png\".format(dir)))\n",
    "\n",
    "live_rgb = np.array(Image.open(\"../data/{0}/live_rgb.png\".format(dir)))\n",
    "live_depth = np.array(Image.open(\"../data/{0}/live_depth.png\".format(dir)))\n",
    "live_mask = np.array(Image.open(\"../data/{0}/live_mask.png\".format(dir)))\n",
    "\n",
    "intrinsics_d415 = np.load(\"../handeye/intrinsics_d415.npy\")\n",
    "intrinsics_d405 = np.load(\"../handeye/intrinsics_d405.npy\")\n",
    "\n",
    "print(live_depth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SceneData(\n",
    "    image_0=demo_rgb,\n",
    "    image_1=live_rgb,\n",
    "    depth_0=demo_depth,\n",
    "    depth_1=live_depth,\n",
    "    seg_0=demo_mask,\n",
    "    seg_1=live_mask,\n",
    "    intrinsics_0=intrinsics_d415,\n",
    "    intrinsics_1=intrinsics_d415,\n",
    "    T_WC=np.eye(4) # cam frame\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.2042055e-05 3.1861695e-05 6.5883150e-04]\n",
      "[9.6279240e-05 7.5559336e-05 5.9681607e-04]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-6.423719e-05, -4.369764e-05,  6.201543e-05], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = Preprocessor()\n",
    "data.update(processor(data))\n",
    "\n",
    "pcd0 = o3d.geometry.PointCloud()\n",
    "pcd0.points = o3d.utility.Vector3dVector(data[\"pc0\"][:, :3])\n",
    "pcd1 = o3d.geometry.PointCloud()\n",
    "pcd1.points = o3d.utility.Vector3dVector(data[\"pc1\"][:, :3])\n",
    "o3d.visualization.draw_geometries([pcd0, pcd1])\n",
    "\n",
    "# Calculate the centroid of each point cloud\n",
    "pcd0_centre = np.mean(data[\"pc0\"][:, :3], axis=0)  # Calculate mean across columns (axis=0)\n",
    "pcd1_centre = np.mean(data[\"pc1\"][:, :3], axis=0)  # Calculate mean across columns (axis=0)\n",
    "\n",
    "print(pcd0_centre)\n",
    "print(pcd1_centre)\n",
    "# # Compute the difference between the centroids\n",
    "diff = pcd0_centre - pcd1_centre\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mesh\n",
    "gripper_mesh = o3d.io.read_triangle_mesh(\"/home/yilong/catkin_ws/src/yumi_oneshot/yumi_description/meshes/gripper/base.stl\")\n",
    "\n",
    "# Check for an empty mesh\n",
    "if gripper_mesh.is_empty():\n",
    "    print(\"Mesh is empty!\")\n",
    "    exit()\n",
    "\n",
    "# Recenter and rescale if necessary\n",
    "gripper_mesh.translate(-gripper_mesh.get_center()) \n",
    "scale = max(gripper_mesh.get_max_bound() - gripper_mesh.get_min_bound())\n",
    "gripper_mesh.scale(1 / scale, center=gripper_mesh.get_center())\n",
    "\n",
    "# Visualization\n",
    "o3d.visualization.draw_geometries([gripper_mesh])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.97040418e-01 -7.62263307e-02  9.99757297e-03  4.49364926e-05]\n",
      " [ 7.61907433e-02  9.97085657e-01  3.89399077e-03  3.21121987e-05]\n",
      " [-1.02652612e-02 -3.12074367e-03  9.99942441e-01 -6.16949763e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "import cv2\n",
    "\n",
    "# Assuming data[\"pc0\"] and data[\"pc1\"] are your point cloud data\n",
    "pcd0 = o3d.geometry.PointCloud()\n",
    "pcd1 = o3d.geometry.PointCloud()\n",
    "\n",
    "pcd0.points = o3d.utility.Vector3dVector(data[\"pc0\"][:, :3])\n",
    "pcd1.points = o3d.utility.Vector3dVector(data[\"pc1\"][:, :3])\n",
    "\n",
    "# Estimate normals for each point cloud\n",
    "pcd0.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=40))\n",
    "pcd1.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=40))\n",
    "\n",
    "# Function to draw registration results\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.transform(transformation)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "# Compute FPFH features\n",
    "voxel_size = 0.05  # Set voxel size for downsampling (adjust based on your data)\n",
    "source_down = pcd0.voxel_down_sample(voxel_size)\n",
    "target_down = pcd1.voxel_down_sample(voxel_size)\n",
    "\n",
    "source_down.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2, max_nn=30))\n",
    "target_down.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2, max_nn=30))\n",
    "\n",
    "source_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "    source_down,\n",
    "    o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 5, max_nn=100))\n",
    "\n",
    "target_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "    target_down,\n",
    "    o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 5, max_nn=100))\n",
    "\n",
    "# Global registration using RANSAC\n",
    "distance_threshold = voxel_size * 1.5\n",
    "result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_down, target_down, source_fpfh, target_fpfh, mutual_filter=False,\n",
    "    max_correspondence_distance=distance_threshold,\n",
    "    estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(), \n",
    "    ransac_n=4,\n",
    "    checkers=[\n",
    "        o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9), \n",
    "        o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "    ],\n",
    "    criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)\n",
    ")\n",
    "\n",
    "# Use the result of global registration as the initial transformation for ICP\n",
    "trans_init = result.transformation\n",
    "\n",
    "# Apply ICP\n",
    "threshold = 0.02  # Set a threshold for ICP, this depends on your data\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    pcd0, pcd1, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "\n",
    "# Get the transformation matrix\n",
    "T_delta_cam = reg_p2p.transformation\n",
    "\n",
    "# Draw the result\n",
    "draw_registration_result(pcd0, pcd1, T_delta_cam)\n",
    "\n",
    "print(T_delta_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04448689, -0.98563898,  0.16290097,  0.41816566],\n",
       "       [-0.014704  , -0.16239872, -0.98661565,  0.33463234],\n",
       "       [ 0.99890175, -0.04628676, -0.00726822, -0.21554994],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_WC = np.load(\"../handeye/T_WC_head.npy\")\n",
    "T_delta_world = T_WC @ T_delta_cam @ pose_inv(T_WC)\n",
    "T_delta_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14343193 0.41713163 0.01285603] [ 2.21225953e-02  1.46855369e+00 -3.23223851e+01]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def translation_from_matrix(matrix):\n",
    "    \"\"\"Extracts the translation vector from a 4x4 homogeneous transformation matrix.\"\"\"\n",
    "    return matrix[:3, 3]\n",
    "\n",
    "def euler_from_matrix(matrix):\n",
    "    \"\"\"Extracts the quaternion from a 4x4 homogeneous transformation matrix.\"\"\"\n",
    "    rotation_matrix = matrix[:3, :3].copy()\n",
    "    rotation = R.from_matrix(rotation_matrix)\n",
    "    return rotation.as_euler(seq=\"XYZ\", degrees=True)\n",
    "\n",
    "trans = translation_from_matrix(T_delta_world)\n",
    "rotation = euler_from_matrix(T_delta_world)\n",
    "\n",
    "print(trans, rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted rotation -1854.694161068739\n",
      "[-0.09844735 -0.39142355 -0.21084177]\n",
      "[[ 0.57794079  0.8160787   0.         -0.09844735]\n",
      " [-0.8160787   0.57794079  0.         -0.39142355]\n",
      " [ 0.          0.          1.         -0.21084177]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "PointCloud = np.ndarray\n",
    "\n",
    "def rotate_pointcloud(pcd: PointCloud, angle_z: float):\n",
    "    print(\"predicted rotation\", np.rad2deg(angle_z))\n",
    "    R = np.eye(3)\n",
    "    cosine = np.cos(angle_z)\n",
    "    sine = np.sin(angle_z)\n",
    "    R[0, 0] = cosine\n",
    "    R[1, 1] = cosine\n",
    "    R[0, 1] = -sine\n",
    "    R[1, 0] = sine\n",
    "\n",
    "    pcd[:3, :] = R @ pcd[:3, :]\n",
    "    return R, pcd\n",
    "\n",
    "def find_translation(pcd0: PointCloud, pcd1: PointCloud) -> np.ndarray:\n",
    "    pcd0_centre = np.mean(pcd0[:3, :], axis=1)\n",
    "    pcd1_centre = np.mean(pcd1[:3, :], axis=1)\n",
    "    return pcd1_centre - pcd0_centre\n",
    "    \n",
    "R_mtx, rotated_pcd0 = rotate_pointcloud(data[\"pc0\"], rotation[-1])\n",
    "translation = find_translation(rotated_pcd0, data[\"pc1\"])\n",
    "\n",
    "print(translation)\n",
    "T_delta_base = np.eye(4)\n",
    "T_delta_base[:3, :3] = R_mtx\n",
    "T_delta_base[:3, 3] = translation\n",
    "\n",
    "T_delta_cam = pose_inv(data[\"T_WC\"]) @ T_delta_base @ data[\"T_WC\"]\n",
    "\n",
    "print(T_delta_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "width = 848  # Replace with your camera image width\n",
    "height = 480 # Replace with your camera image height\n",
    "fx = 431.56503296\n",
    "fy = 431.18637085\n",
    "cx = 418.71490479\n",
    "cy = 235.15617371 \n",
    "intrinsics = o3d.camera.PinholeCameraIntrinsic(width, height, fx, fy, cx, cy)\n",
    "\n",
    "demo_mask = np.array(Image.open(\"../data/lego/demo_wrist_mask.png\"))\n",
    "demo_rgb = np.array(Image.open(\"../data/lego/demo_wrist_rgb.png\")) \n",
    "demo_depth = np.array(Image.open(\"../data/lego/demo_wrist_depth.png\")).astype(np.uint16)\n",
    "\n",
    "color = o3d.geometry.Image(demo_rgb)\n",
    "depth = o3d.geometry.Image(demo_depth)\n",
    "\n",
    "rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    color, depth, depth_scale=1000.0, convert_rgb_to_intensity=False)\n",
    "\n",
    "rgbd_image\n",
    "pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd_image, intrinsics) \n",
    "\n",
    "# Visualization\n",
    "o3d.visualization.draw_geometries([pcd]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
