{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from direct.preprocessor import Preprocessor, pose_inv, SceneData\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "demo_rgb = np.array(Image.open(\"../data/demo_spray_rgb.png\"))\n",
    "demo_depth = np.array(Image.open(\"../data/demo_spray_depth.png\"))\n",
    "demo_mask = np.array(Image.open(\"../data/demo_spray_mask.png\"))\n",
    "\n",
    "live_rgb = np.array(Image.open(\"../data/live_spray_rgb.png\"))\n",
    "live_depth = np.array(Image.open(\"../data/live_spray_depth.png\"))\n",
    "live_mask = np.array(Image.open(\"../data/live_spray_mask.png\"))\n",
    "T_WC = np.load(\"../handeye/T_WC_head.npy\")\n",
    "intrinsics = np.load(\"../handeye/intrinsics.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SceneData(\n",
    "    image_0=demo_rgb,\n",
    "    image_1=live_rgb,\n",
    "    depth_0=demo_depth,\n",
    "    depth_1=live_depth,\n",
    "    seg_0=demo_mask,\n",
    "    seg_1=live_mask,\n",
    "    intrinsics_0=intrinsics,\n",
    "    intrinsics_1=intrinsics,\n",
    "    T_WC=T_WC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (48743,) (47802,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/yilong/catkin_ws/src/yumi_oneshot/PoseEst/icp.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yilong/catkin_ws/src/yumi_oneshot/PoseEst/icp.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m pcd0_centre \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(data[\u001b[39m\"\u001b[39m\u001b[39mpc0\u001b[39m\u001b[39m\"\u001b[39m][:, :\u001b[39m3\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yilong/catkin_ws/src/yumi_oneshot/PoseEst/icp.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m pcd1_centre \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(data[\u001b[39m\"\u001b[39m\u001b[39mpc1\u001b[39m\u001b[39m\"\u001b[39m][:, :\u001b[39m3\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/yilong/catkin_ws/src/yumi_oneshot/PoseEst/icp.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m diff \u001b[39m=\u001b[39m pcd0_centre \u001b[39m-\u001b[39;49m pcd1_centre\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/yilong/catkin_ws/src/yumi_oneshot/PoseEst/icp.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m diff\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (48743,) (47802,) "
     ]
    }
   ],
   "source": [
    "processor = Preprocessor()\n",
    "data.update(processor(data))\n",
    "\n",
    "pcd0 = o3d.geometry.PointCloud()\n",
    "pcd0.points = o3d.utility.Vector3dVector(data[\"pc0\"][:, :3])\n",
    "pcd1 = o3d.geometry.PointCloud()\n",
    "pcd1.points = o3d.utility.Vector3dVector(data[\"pc1\"][:, :3])\n",
    "o3d.visualization.draw_geometries([pcd0, pcd1])\n",
    "\n",
    "pcd0_centre = np.mean(data[\"pc0\"][:, :3], axis=1)\n",
    "pcd1_centre = np.mean(data[\"pc1\"][:, :3], axis=1)\n",
    "diff = pcd0_centre - pcd1_centre\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.45253333e-01  5.33840498e-01  2.36881046e-02  1.43716325e-01]\n",
      " [-5.33995876e-01  8.45487035e-01  2.77532636e-04  4.16363865e-01]\n",
      " [-1.98798272e-02 -1.28839356e-02  9.99719359e-01  1.16154340e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "import cv2\n",
    "\n",
    "# Assuming data[\"pc0\"] and data[\"pc1\"] are your point cloud data\n",
    "pcd0 = o3d.geometry.PointCloud()\n",
    "pcd1 = o3d.geometry.PointCloud()\n",
    "\n",
    "pcd0.points = o3d.utility.Vector3dVector(data[\"pc0\"][:, :3])\n",
    "pcd1.points = o3d.utility.Vector3dVector(data[\"pc1\"][:, :3])\n",
    "\n",
    "# Estimate normals for each point cloud\n",
    "pcd0.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=40))\n",
    "pcd1.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=40))\n",
    "\n",
    "# Function to draw registration results\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.transform(transformation)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "# Compute FPFH features\n",
    "voxel_size = 0.05  # Set voxel size for downsampling (adjust based on your data)\n",
    "source_down = pcd0.voxel_down_sample(voxel_size)\n",
    "target_down = pcd1.voxel_down_sample(voxel_size)\n",
    "\n",
    "source_down.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2, max_nn=30))\n",
    "target_down.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2, max_nn=30))\n",
    "\n",
    "source_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "    source_down,\n",
    "    o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 5, max_nn=100))\n",
    "\n",
    "target_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "    target_down,\n",
    "    o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 5, max_nn=100))\n",
    "\n",
    "# Global registration using RANSAC\n",
    "distance_threshold = voxel_size * 1.5\n",
    "result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "    source_down, target_down, source_fpfh, target_fpfh, mutual_filter=False,\n",
    "    max_correspondence_distance=distance_threshold,\n",
    "    estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(), \n",
    "    ransac_n=4,\n",
    "    checkers=[\n",
    "        o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9), \n",
    "        o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "    ],\n",
    "    criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)\n",
    ")\n",
    "\n",
    "# Use the result of global registration as the initial transformation for ICP\n",
    "trans_init = result.transformation\n",
    "\n",
    "# Apply ICP\n",
    "threshold = 0.02  # Set a threshold for ICP, this depends on your data\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    pcd0, pcd1, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "\n",
    "# Get the transformation matrix\n",
    "T_delta_base = reg_p2p.transformation\n",
    "\n",
    "# Draw the result\n",
    "draw_registration_result(pcd0, pcd1, T_delta_base)\n",
    "\n",
    "print(T_delta_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14371632 0.41636387 0.01161543] [-1.59059122e-02  1.35735538e+00 -3.22754644e+01]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def translation_from_matrix(matrix):\n",
    "    \"\"\"Extracts the translation vector from a 4x4 homogeneous transformation matrix.\"\"\"\n",
    "    return matrix[:3, 3]\n",
    "\n",
    "def euler_from_matrix(matrix):\n",
    "    \"\"\"Extracts the quaternion from a 4x4 homogeneous transformation matrix.\"\"\"\n",
    "    rotation_matrix = matrix[:3, :3].copy()\n",
    "    rotation = R.from_matrix(rotation_matrix)\n",
    "    return rotation.as_euler(seq=\"XYZ\", degrees=True)\n",
    "\n",
    "trans = translation_from_matrix(T_delta_base)\n",
    "rotation = euler_from_matrix(T_delta_base)\n",
    "\n",
    "print(trans, rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted rotation -1854.694161068739\n",
      "[-0.09844735 -0.39142355 -0.21084177]\n",
      "[[ 0.57794079  0.8160787   0.         -0.09844735]\n",
      " [-0.8160787   0.57794079  0.         -0.39142355]\n",
      " [ 0.          0.          1.         -0.21084177]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "PointCloud = np.ndarray\n",
    "\n",
    "def rotate_pointcloud(pcd: PointCloud, angle_z: float):\n",
    "    print(\"predicted rotation\", np.rad2deg(angle_z))\n",
    "    R = np.eye(3)\n",
    "    cosine = np.cos(angle_z)\n",
    "    sine = np.sin(angle_z)\n",
    "    R[0, 0] = cosine\n",
    "    R[1, 1] = cosine\n",
    "    R[0, 1] = -sine\n",
    "    R[1, 0] = sine\n",
    "\n",
    "    pcd[:3, :] = R @ pcd[:3, :]\n",
    "    return R, pcd\n",
    "\n",
    "def find_translation(pcd0: PointCloud, pcd1: PointCloud) -> np.ndarray:\n",
    "    pcd0_centre = np.mean(pcd0[:3, :], axis=1)\n",
    "    pcd1_centre = np.mean(pcd1[:3, :], axis=1)\n",
    "    return pcd1_centre - pcd0_centre\n",
    "    \n",
    "R_mtx, rotated_pcd0 = rotate_pointcloud(data[\"pc0\"], rotation[-1])\n",
    "translation = find_translation(rotated_pcd0, data[\"pc1\"])\n",
    "\n",
    "print(translation)\n",
    "T_delta_base = np.eye(4)\n",
    "T_delta_base[:3, :3] = R_mtx\n",
    "T_delta_base[:3, 3] = translation\n",
    "\n",
    "T_delta_cam = pose_inv(data[\"T_WC\"]) @ T_delta_base @ data[\"T_WC\"]\n",
    "\n",
    "print(T_delta_base)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
