{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import TypedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SceneData(TypedDict):\n",
    "    image_0: np.ndarray\n",
    "    image_1: np.ndarray\n",
    "    depth_0: np.ndarray\n",
    "    depth_1: np.ndarray\n",
    "    seg_0: np.ndarray\n",
    "    seg_1: np.ndarray\n",
    "    intrinsics_0: np.ndarray\n",
    "    intrinsics_1: np.ndarray\n",
    "    T_WC: np.ndarray\n",
    "\n",
    "\n",
    "class ProcessedData(TypedDict):\n",
    "    pointcloud_0: np.ndarray\n",
    "    pointcloud_1: np.ndarray\n",
    "\n",
    "\n",
    "def pose_inv(pose):\n",
    "    R = pose[:3, :3]\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R.T\n",
    "    T[:3, 3] = - R.T @ np.ascontiguousarray(pose[:3, 3])\n",
    "    return T\n",
    "\n",
    "\n",
    "class Preprocessor():\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_points: int = 2048,\n",
    "                 filter_pointcloud: bool = True,\n",
    "                 filter_outliers_o3d: bool = False,\n",
    "                 debug: bool = False) -> None:\n",
    "\n",
    "        self.debug_mode = debug\n",
    "\n",
    "        self.n_points = n_points\n",
    "        self.filter_pointcloud = filter_pointcloud\n",
    "        self.filter_outliers_o3d = filter_outliers_o3d\n",
    "\n",
    "        if filter_pointcloud and filter_outliers_o3d:\n",
    "            logging.warning(\"[WARNING] You are both filtering the pointcloud with heuristics and with Open3D\")\n",
    "        elif filter_outliers_o3d:\n",
    "            raise NotImplementedError(\"[Open3D] Pointcloud outlier filtering is not implemented\")\n",
    "            logging.warning(\"[WARNING] The Open3D parameters for filtering outliers might have to be tuned\")\n",
    "\n",
    "    def _initial_processing(self, data: SceneData):\n",
    "        data[\"seg_0\"] = data[\"seg_0\"].astype(bool)\n",
    "        data[\"seg_1\"] = data[\"seg_1\"].astype(bool)\n",
    "\n",
    "        data[\"depth_0\"] = data[\"depth_0\"] / 1000\n",
    "        data[\"depth_1\"] = data[\"depth_1\"] / 1000\n",
    "        data[\"depth_0\"] = data[\"depth_0\"] * (data[\"depth_0\"] < 5.0) * data[\"seg_0\"]\n",
    "        data[\"depth_1\"] = data[\"depth_1\"] * (data[\"depth_1\"] < 5.0) * data[\"seg_1\"]\n",
    "\n",
    "        data[\"image_0\"] = data[\"image_0\"].astype(np.float32)\n",
    "        data[\"image_1\"] = data[\"image_1\"].astype(np.float32)\n",
    "        data[\"depth_0\"] = data[\"depth_0\"].astype(np.float32)\n",
    "        data[\"depth_1\"] = data[\"depth_1\"].astype(np.float32)\n",
    "\n",
    "    def _get_segmented_keypoints(self, seg: np.ndarray):\n",
    "        x = np.arange(seg.shape[1], dtype=int)  # TODO should we have '+ 0.5' here?\n",
    "        y = np.arange(seg.shape[0], dtype=int)  # TODO should we have '+ 0.5' here?\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "        indices = np.concatenate((xx[seg][..., None], yy[seg][..., None]), axis=1)\n",
    "        return indices\n",
    "\n",
    "    def get_filtered_depth_ids(self, depth: np.ndarray, seg: np.ndarray):\n",
    "        n_smallest = 500\n",
    "        std_scale = 4\n",
    "        seg_flat_depth = depth.reshape(-1)[seg.reshape(-1)]\n",
    "\n",
    "        semi_sorted_args = np.argpartition(-seg_flat_depth[:], n_smallest)  # get arg of 50 largest values\n",
    "        largest_values = seg_flat_depth[semi_sorted_args[:n_smallest]]\n",
    "\n",
    "        mean, std = np.mean(largest_values), np.std(largest_values)\n",
    "        filter_args = seg_flat_depth[:] > (mean + std_scale * std)\n",
    "\n",
    "        # semi_sorted_args = np.argpartition(seg_flat_depth[:], n_smallest) #get arg of 50 smallest values\n",
    "        # smallest_values = seg_flat_depth[semi_sorted_args[:n_smallest]]\n",
    "\n",
    "        # mean, std = np.mean(smallest_values), np.std(smallest_values)\n",
    "        # filter_args += seg_flat_depth[:] < (mean - std_scale * std)\n",
    "\n",
    "        return ~filter_args\n",
    "\n",
    "    def project_pointcloud(self,\n",
    "                           keypoints: np.ndarray,\n",
    "                           depth_image: np.ndarray,\n",
    "                           K0: np.ndarray,\n",
    "                           depth_units: str = 'mm'):\n",
    "\n",
    "        # Get the depth value of the keypoint\n",
    "        depth_values_0 = np.empty((keypoints.shape[0], 1))\n",
    "        for i in range(keypoints.shape[0]):\n",
    "            depth_values_0[i, 0] = depth_image[keypoints[i, 1], keypoints[i, 0]]\n",
    "\n",
    "        if depth_units == 'mm':\n",
    "            depth_values_0 = depth_values_0 / 1e3\n",
    "\n",
    "        # Get the position of the keypoint in the camera frame\n",
    "        keypoint_pos_C_0 = depth_values_0 * np.concatenate((keypoints, np.ones((len(keypoints), 1))),\n",
    "                                                           axis=1) @ np.linalg.inv(K0).T\n",
    "        return keypoint_pos_C_0\n",
    "\n",
    "    def _get_pointclouds(self, data: SceneData):\n",
    "        K = data[\"intrinsics_0\"]\n",
    "        depth = data[\"depth_0\"]\n",
    "        keypoints = self._get_segmented_keypoints(data['seg_0'])\n",
    "        projected_keypoints = self.project_pointcloud(keypoints, depth, K, 'm')\n",
    "        if self.filter_pointcloud:\n",
    "            valid_keypoints = projected_keypoints[:, 2] != 0\n",
    "            data['pc0_keep_id'] = (self.get_filtered_depth_ids(data[\"depth_0\"], data[\"seg_0\"]).astype(\n",
    "                int) + valid_keypoints.astype(int)) == 2\n",
    "        projected_keypoints = np.concatenate((projected_keypoints, np.ones((projected_keypoints.shape[0], 1))),\n",
    "                                             axis=1).transpose(1, 0)\n",
    "        data['pc0'] = (data[\"T_WC\"] @ projected_keypoints).astype(np.float32)\n",
    "        data['pc0'] = data[\"pc0\"].transpose(1, 0)[:, :3]\n",
    "        # print(np.min(crop_data['pc0'][:,2]), np.max(crop_data['pc0'][:,2]))\n",
    "\n",
    "        K = data[\"intrinsics_1\"]\n",
    "        depth = data[\"depth_1\"]\n",
    "        keypoints = self._get_segmented_keypoints(data['seg_1'])\n",
    "        projected_keypoints = self.project_pointcloud(keypoints, depth, K, 'm')\n",
    "        if self.filter_pointcloud:\n",
    "            valid_keypoints = projected_keypoints[:, 2] != 0\n",
    "            data['pc1_keep_id'] = (self.get_filtered_depth_ids(data[\"depth_1\"], data[\"seg_1\"]).astype(\n",
    "                int) + valid_keypoints.astype(int)) == 2\n",
    "        projected_keypoints = np.concatenate((projected_keypoints, np.ones((projected_keypoints.shape[0], 1))),\n",
    "                                             axis=1).transpose(1, 0)\n",
    "        data['pc1'] = (data[\"T_WC\"] @ projected_keypoints).astype(np.float32)\n",
    "        data['pc1'] = data[\"pc1\"].transpose(1, 0)[:, :3]\n",
    "\n",
    "    def __call__(self, data: SceneData) -> ProcessedData:\n",
    "\n",
    "        self._initial_processing(data)\n",
    "        self._get_pointclouds(data)\n",
    "\n",
    "        data[\"image_0\"] = data[\"image_0\"] / 255 * 2 - 1\n",
    "        data[\"image_1\"] = data[\"image_1\"] / 255 * 2 - 1\n",
    "\n",
    "        rgb_data = data[\"image_0\"].transpose(1, 2, 0).reshape(-1, 3)\n",
    "        rgb_data = rgb_data[data[\"seg_0\"].reshape(-1), :]\n",
    "        data[\"pc0\"] = np.concatenate((data[\"pc0\"], rgb_data), axis=1)\n",
    "\n",
    "        rgb_data = data[\"image_1\"].transpose(1, 2, 0).reshape(-1, 3)\n",
    "        rgb_data = rgb_data[data[\"seg_1\"].reshape(-1), :]\n",
    "        data[\"pc1\"] = np.concatenate((data[\"pc1\"], rgb_data), axis=1)\n",
    "\n",
    "        data[\"pc0\"] = data[\"pc0\"][data['pc0_keep_id'], :]\n",
    "        data[\"pc1\"] = data[\"pc1\"][data['pc1_keep_id'], :]\n",
    "\n",
    "        sample_args = np.random.randint(low=0, high=data[\"pc0\"].shape[0], size=self.n_points)\n",
    "        data[\"pc0\"] = data[\"pc0\"][sample_args, :]\n",
    "        sample_args = np.random.randint(low=0, high=data[\"pc1\"].shape[0], size=self.n_points)\n",
    "        data[\"pc1\"] = data[\"pc1\"][sample_args, :]\n",
    "\n",
    "        data[\"pc0\"] = np.concatenate((data[\"pc0\"], data[\"pc0\"][:, :3]), axis=1)\n",
    "        data[\"pc1\"] = np.concatenate((data[\"pc1\"], data[\"pc1\"][:, :3]), axis=1)\n",
    "\n",
    "        # import open3d as o3d\n",
    "        # pcd0 = o3d.geometry.PointCloud()\n",
    "        # pcd0.points = o3d.utility.Vector3dVector(data[\"pc0\"][:, :3])\n",
    "        # pcd1 = o3d.geometry.PointCloud()\n",
    "        # pcd1.points = o3d.utility.Vector3dVector(data[\"pc1\"][:, :3])\n",
    "        # o3d.visualization.draw_geometries([pcd0, pcd1])\n",
    "\n",
    "        return {\n",
    "            'pointcloud_0': data[\"pc0\"].transpose(1, 0).astype(np.float32),  # (1, 9, n_points)\n",
    "            'pointcloud_1': data[\"pc1\"].transpose(1, 0).astype(np.float32),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01084383, -0.73173649,  0.68150137,  0.12040806],\n",
       "       [-0.99979779, -0.01947678, -0.00500401,  0.02701207],\n",
       "       [ 0.01693506, -0.6813093 , -0.73179973,  0.52563764],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_WC = np.load(\"../T_WC_head.npy\")\n",
    "T_WC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'handeye/T_WC_head.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/yilong/catkin_ws/src/yumi_oneshot/PoseEst/direct/pc_registration.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/yilong/catkin_ws/src/yumi_oneshot/PoseEst/direct/pc_registration.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m T_WC \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mhandeye/T_WC_head.npy\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/yilong/catkin_ws/src/yumi_oneshot/PoseEst/direct/pc_registration.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m T_WC\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'handeye/T_WC_head.npy'"
     ]
    }
   ],
   "source": [
    "T_WC = np.load(\".../handeye/T_WC_head.npy\")\n",
    "T_WC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
